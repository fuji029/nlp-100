{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章: 形態素解析\n",
    "\n",
    "夏目漱石の小説『吾輩は猫である』の文章（[neko.txt](./neko.txt)）をMeCabを使って形態素解析し，その結果をneko.txt.mecabというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ．\n",
    "\n",
    "なお，問題37, 38, 39は[matplotlib](http://matplotlib.org/)もしくは[Gnuplot](http://www.gnuplot.info/)を用いるとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩\tワガハイ\tワガハイ\t我が輩\t代名詞\t\t\t0\n",
      "は\tワ\tハ\tは\t助詞-係助詞\t\t\t\n",
      "猫\tネコ\tネコ\t猫\t名詞-普通名詞-一般\t\t\t1\n",
      "で\tデ\tダ\tだ\t助動詞\t助動詞-ダ\t連用形-一般\t\n",
      "ある\tアル\tアル\t有る\t動詞-非自立可能\t五段-ラ行\t終止形-一般\t1\n",
      "。\t\t\t。\t補助記号-句点\t\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "tagger = MeCab.Tagger()\n",
    "print(tagger.parse(\"吾輩は猫である。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "with open(\"neko.txt\", \"r\") as f:\n",
    "    lines = f.read().rstrip().split(\"\\n\")\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "\n",
    "result = []\n",
    "for line in lines:\n",
    "    result.append(tagger.parse(line))\n",
    "\n",
    "with open(\"neko.txt.mecab\", \"w\") as f:\n",
    "    f.writelines(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30. 形態素解析結果の読み込み\n",
    "\n",
    "形態素解析結果（neko.txt.mecab）を読み込むプログラムを実装せよ．ただし，各形態素は表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をキーとするマッピング型に格納し，1文を形態素（マッピング型）のリストとして表現せよ．第4章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'base': '一', 'pos': '名詞', 'pos1': '数詞', 'surface': '一'}],\n",
      " [{'base': '我が輩', 'pos': '代名詞', 'pos1': '*', 'surface': '吾輩'},\n",
      "  {'base': 'は', 'pos': '助詞', 'pos1': '係助詞', 'surface': 'は'},\n",
      "  {'base': '猫', 'pos': '名詞', 'pos1': '普通名詞', 'surface': '猫'},\n",
      "  {'base': 'だ', 'pos': '助動詞', 'pos1': '*', 'surface': 'で'},\n",
      "  {'base': '有る', 'pos': '動詞', 'pos1': '非自立可能', 'surface': 'ある'},\n",
      "  {'base': '。', 'pos': '補助記号', 'pos1': '句点', 'surface': '。'}],\n",
      " [{'base': '名前', 'pos': '名詞', 'pos1': '普通名詞', 'surface': '名前'},\n",
      "  {'base': 'は', 'pos': '助詞', 'pos1': '係助詞', 'surface': 'は'},\n",
      "  {'base': '未だ', 'pos': '副詞', 'pos1': '*', 'surface': 'まだ'},\n",
      "  {'base': '無い', 'pos': '形容詞', 'pos1': '非自立可能', 'surface': '無い'},\n",
      "  {'base': '。', 'pos': '補助記号', 'pos1': '句点', 'surface': '。'}]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"neko.txt.mecab\", \"r\") as f:\n",
    "    lines = f.read().rstrip().split(\"\\n\")\n",
    "\n",
    "POS_list = []\n",
    "l = []\n",
    "for line in lines:\n",
    "    dic = {}\n",
    "    if(line == \"EOS\"):\n",
    "        if(len(l)):\n",
    "            POS_list.append(l)\n",
    "        l = []\n",
    "    else: \n",
    "        line = line.split(\"\\t\", 5)\n",
    "        dic[\"surface\"] = line[0]\n",
    "        dic[\"base\"] = line[3]\n",
    "        pos = line[4].split(\"-\")\n",
    "        dic[\"pos\"] = pos[0]\n",
    "        try:\n",
    "            dic[\"pos1\"] = pos[1]\n",
    "        except:\n",
    "            dic[\"pos1\"] = \"*\"\n",
    "        if(dic[\"pos\"] == \"空白\"):\n",
    "            continue\n",
    "        l.append(dic)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(POS_list[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31. 動詞\n",
    "動詞の表層形をすべて抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['儲かっ', '得', '事足る', '覚め', '付い', '欲する', '為し', '鳴らさ', '動け', 'よし']\n"
     ]
    }
   ],
   "source": [
    "verb_surface_set = set()\n",
    "for poss in POS_list:\n",
    "    for pos in poss:\n",
    "        if(pos[\"pos\"] == \"動詞\"):\n",
    "            verb_surface_set.add(pos[\"surface\"])\n",
    "pprint(list(verb_surface_set)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32. 動詞の基本形\n",
    "動詞の基本形をすべて抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['涼む', '事足る', '犯す', '欲する', '掻き毟る', '仕舞い込む', '合わせる', '揉み潰す', '罵り返す', 'ごねる']\n"
     ]
    }
   ],
   "source": [
    "verb_base_set = set()\n",
    "for poss in POS_list:\n",
    "    for pos in poss:\n",
    "        if(pos[\"pos\"] == \"動詞\"):\n",
    "            verb_base_set.add(pos[\"base\"])\n",
    "pprint(list(verb_base_set)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33. 「AのB」\n",
    "2つの名詞が「の」で連結されている名詞句を抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['掌の上', '書生の顔', 'ものの見', 'はずの顔', '顔の真中', '穴の中', '書生の掌', '掌の裏', '藁の上', '笹原の中']\n"
     ]
    }
   ],
   "source": [
    "B_of_A = list()\n",
    "for poss in POS_list:\n",
    "    for i, pos in enumerate(poss):\n",
    "        if(i == 0 or i == len(poss) - 1):\n",
    "            continue\n",
    "        if(pos[\"surface\"] == \"の\" and pos[\"pos1\"] == \"格助詞\"):\n",
    "            if(poss[i-1][\"pos\"] == \"名詞\" and poss[i+1][\"pos\"] == \"名詞\"):\n",
    "                B_of_A.append(poss[i-1][\"surface\"] + pos[\"surface\"] + poss[i+1][\"surface\"])\n",
    "pprint(B_of_A[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34. 名詞の連接\n",
    "名詞の連接（連続して出現する名詞）を最長一致で抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['見始', '時妙', '一毛', '後猫', '一度', '上今', 'うち池', '書生以外', '間おさん', '宿なし']\n"
     ]
    }
   ],
   "source": [
    "nouns = []\n",
    "all_pos_list = []\n",
    "for poss in POS_list:\n",
    "    for pos in poss:\n",
    "        all_pos_list.append(pos)\n",
    "for i, pos in enumerate(all_pos_list):\n",
    "    if(pos[\"pos\"] == \"名詞\"):\n",
    "        nouns.append([i, pos[\"surface\"]])\n",
    "\n",
    "result = []\n",
    "flag = [False] * len(nouns)\n",
    "for i in range(len(nouns) - 1):\n",
    "    if(flag[i]):\n",
    "        continue\n",
    "    flag[i] = True\n",
    "    l = [nouns[i][1]]\n",
    "    j = i + 1\n",
    "    idx = nouns[i][0]\n",
    "    while(j < len(nouns) and nouns[j][0] == idx + 1):\n",
    "        l.append(nouns[j][1])\n",
    "        idx = nouns[j][0]\n",
    "        flag[j] = True\n",
    "        j += 1\n",
    "    if(len(l) > 1):\n",
    "        result.append(l)\n",
    "\n",
    "for i in range(len(result)):\n",
    "    result[i] = \"\".join(result[i])\n",
    "\n",
    "pprint(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35. 単語の出現頻度\n",
    "文章中に出現する単語とその出現頻度を求め，出現頻度の高い順に並べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['の', 9541],\n",
      " ['。', 7486],\n",
      " ['て', 7418],\n",
      " ['に', 7060],\n",
      " ['、', 6773],\n",
      " ['は', 6501],\n",
      " ['と', 6156],\n",
      " ['を', 6119],\n",
      " ['が', 5394],\n",
      " ['で', 4543]]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(int)\n",
    "\n",
    "for pos in all_pos_list:\n",
    "    d[pos[\"surface\"]] += 1\n",
    "\n",
    "sorted_d = sorted(d.items(), key=lambda x:x[1], reverse=True)\n",
    "for i in range(len(sorted_d)):\n",
    "    sorted_d[i] = list(sorted_d[i])\n",
    "pprint(sorted_d[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36. 頻度上位10語\n",
    "出現頻度が高い10語とその出現頻度をグラフ（例えば棒グラフなど）で表示せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37. 「猫」と共起頻度の高い上位10語\n",
    "「猫」とよく共起する（共起頻度が高い）10語とその出現頻度をグラフ（例えば棒グラフなど）で表示せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38. ヒストグラム\n",
    "単語の出現頻度のヒストグラムを描け．ただし，横軸は出現頻度を表し，1から単語の出現頻度の最大値までの線形目盛とする．縦軸はx軸で示される出現頻度となった単語の異なり数（種類数）である．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 39. Zipfの法則\n",
    "単語の出現頻度順位を横軸，その出現頻度を縦軸として，両対数グラフをプロットせよ．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
